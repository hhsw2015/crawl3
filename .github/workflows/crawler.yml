name: Pornrips Crawler

on:
  workflow_dispatch:  # 手动触发
    inputs:
      start_page:
        description: 'Start page number'
        required: true
        default: '5946'
      end_page:
        description: 'End page number'
        required: true
        default: '1'

jobs:
  crawl:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install requests beautifulsoup4 tqdm

    - name: Run crawler
      env:
        START_PAGE: ${{ github.event.inputs.start_page }}
        END_PAGE: ${{ github.event.inputs.end_page }}
      run: python crawler.py

    - name: Commit and push changes
      run: |
        git config --global user.email "your-email@example.com"
        git config --global user.name "your-username"
        git add pornrips_data.csv
        git commit -m "Update crawled data" || echo "No changes to commit"
        git push
      env:
        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
